#cloud-config

hostname: HostName

# include one or more SSH public keys
ssh_authorized_keys:
  - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCxX2im4hTlGi2+oUaqzmguRmXOoHqFofvSILYegBHu2cmu3cHMFyQX9mBa2qVJ/+d6F/lfJ1XX4OYxPwtEe4YHgzsUzvUgZod3x2hoim2uOGaf0BoRdTAnQxY6Tum9fylI+MzMmDLFR1d2G3AzGyDPc9baZJWVCElNLbeq47sXITiVl5j52u+WHPRnEy/PMIX5amLPWTBYPds7qF8zlUJaM6r9xedFyyv2t5J/6Zn755f0S9rEVw5ga8H71qj4d9MgaHF5DjLS46ml5lL7vmNpk2wdIL54ncZ5a/I4JcFsnhycrBIXVoaq+aubstyByG6S8qa4OqSPOIaHvfaIK9fNcffVoTzjGNyZo5yy2qEemSPQ0emSp0CiuGra7E4cPnbhFdfEJHXOz7+TJ5CwY0QvR6wEOr0t5PxzHZsI4aoKvrrEeoeua9guZmRU41SujCvi4sDSXRVfxyq6yLhk9kVS4/zbXIsANN9p9CkeXUsZiAqUv6d+rRXY2kuh0S5aM9a1GoRHbfYxeNIXeko3hkJnl9CFtd2qnio0L+vLF55wvuvYgoxmW/YtNfIsI8DO43+Ydez7SIGfauuErBqPhAUYL2U5S4i8p/Oqnzuxm755R5/yXO3Wxko27LC09YhnZGk8AswsIv3rdgYiNscDQMZorya5WH4lnJjkJnmmOh44mw== jaohaohsuan@gmail.com
  - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCmUIsevaUMci2lwlj4TYbnH/jS28VBmeJT5KxpT4ku9AZFVnNEfX1C0ZdNF7wW1V1k+Cj3Vzc4KZeBja5imsY/ynmkxsDmrhO5Fga6AtWqottz9HbQNvesjfLfx5/QoGaRycH2r5BZhbCTuRGpiKXKvAh9EmyFFdxb2di+6J4QbwGruF3zWTTijcq70Ip+Dsdfottq2hkNIFIzdgxFm0eXVMOnFEek5AEiCYKYF9VQHjT0NGFqaT4LQPXE3q3Ibox8FgG2T72DlK3YZaxLEKsy2QMpgEFu877cj/oFwLi8V3megOfEjKItuI7UrCml2jmXEBwc9ufEJvy9rfGH4x8wyji90omPAUqMJKfSCJ5H7v0PfwQnM7xxw50kTA741qC5GACZ+PAKsrjC0K6VZ5tAQGtkEvqa5FFUX8w/Q5Yg+RzNdY9o55SOuKf8K2FyUR4qJy/PNATPUnqvW0mocluW+PXBFdwnleHl6pDUObrYsXkQKJ1sHw74tWJHPsgpL7ffZjpRt8KBRKKMaBp2P01+xXhk1Ar86blgyXzMlrw+ia+VlnGkRNeYfV9l3NHYh+rEic6A8T/6XqAgbjtrQyCKjRMwATDUk4rFctpVQP7zURHzPo9Y+/z+RQzHQKDBqcj3BjbQZAwuP+9viqZ+vzXb724UIC1X6eBan7xlNJMDBw== jaohaohsuan@gmail.com

write_files:
  - path: /etc/kubelet-rkt
    owner: root
    permissions: "0644"
    content: |
      RKT_OPTS="--volume etc-cni-netd,kind=host,source=/etc/cni/net.d,readOnly=false --volume opt-cni-bin,kind=host,source=/opt/cni/bin,readOnly=false --mount volume=etc-cni-netd,target=/etc/cni/net.d --mount volume=opt-cni-bin,target=/opt/cni/bin"
      KUBELET_ARGS="--network-plugin=cni --pod-manifest-path=/etc/kubernetes/manifests --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --kubeconfig=/etc/kubernetes/kubelet.conf --require-kubeconfig=true --allow-privileged=true --node-labels='node=storage'"

  - path: /etc/hosts
    content: |
      127.0.0.1 localhost
      ServerIPAddress HostName


coreos:
  etcd2:
    name: etcdserver
    initial-cluster: etcdserver=http://ServerIPAddress:2380
    initial-advertise-peer-urls: http://ServerIPAddress:2380
    advertise-client-urls: http://ServerIPAddress:2379
    # listen on both the official ports and the legacy ports
    # legacy ports can be omitted if your application doesn't depend on them
    listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
    listen-peer-urls: http://0.0.0.0:2380

  units:
    - name: 00-eth0.network
      runtime: true
      content: |
        [Match]
        Name=eth0

        [Network]
        DNS=168.95.1.1
        Address=ServerIPAddress/24
        Gateway=RouterIP

    - name: coreos-installd.service
      command: start
      content: |
        [Unit]
        Description=coreos-installd
        Requires=network-online.target
        After=network-online.target
        ConditionPathExists=!/.check_coreos-installd.service

        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/bin/bash -c 'wget -O - http://iPXE_Server_IP/bin/coreos-installd.sh | bash -'

        [Install]
        WantedBy=multi-user.target

    # set timezone Asia/Taipei
    - name: timezone.service
      command: start
      content: |
        [Unit]
        Description=timezone

        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/usr/bin/ln -sf /usr/share/zoneinfo/Asia/Taipei /etc/localtime

        [Install]
        WantedBy=multi-user.target

    - name: etcd2.service
      command: start

    - name: rkt-metadata.socket
      command: start

    - name: rkt-metadata.service
      command: start

    - name: rkt-api.service
      command: start
      content: |
        [Unit]
        Description=rkt api service
        Documentation=http://github.com/coreos/rkt
        After=network.target

        [Service]
        ExecStart=/usr/bin/rkt api-service --listen=0.0.0.0:15441

        [Install]
        WantedBy=multi-user.target

    - name: kubelet.service
      command: start
      content: |
        [Unit]
        Requires=docker.service
        After=docker.service

        [Service]
        EnvironmentFile=/etc/kubelet-rkt
        Environment=KUBELET_VERSION=vK8SVersion_coreos.0
        ExecStart=/usr/lib/coreos/kubelet-wrapper $KUBELET_ARGS

        KillMode=mixed
        Restart=always
        RestartSec=10

        [Install]
        WantedBy=multi-user.target

    - name: create-kubelet-config.service
      command: start
      content: |
        [Unit]
        Description=Create kubelet necessary configuration file
        ConditionPathExists=!/etc/kubernetes/kubelet.conf

        [Service]
        Environment=KUBE_HYPERKUBE_IMAGE=gcr.io/google_containers/hyperkube-amd64:vK8SVersion
        ExecStartPre=/usr/bin/ls /.check_coreos-installd.service
        RemainAfterExit=yes
        ExecStart=/opt/bin/kubeadm init --token=KubernetesToken --skip-preflight-checks --use-kubernetes-version vK8SVersion \
            --api-advertise-addresses ServerIPAddress --external-etcd-endpoints http://ServerIPAddress:2379
        Restart=always
        RestartSec=5
        
        [Install]
        WantedBy=multi-user.target

    - name: taint-master.service
      command: start
      content: |
        [Unit]
        Description=taint master to K8S

        [Service]
        RemainAfterExit=yes
        ExecStartPre=/usr/bin/bash -c \
            "/opt/bin/kubectl get node master.example.org -o yaml | grep 'scheduler.alpha.kubernetes.io/taints:.*NoSchedule'"
        ExecStart=/opt/bin/kubectl taint nodes --all dedicated-
        Restart=always
        RestartSec=5

        [Install]
        WantedBy=multi-user.target

    - name: calico-installd.service
      command: start
      content: |
        [Unit]
        ConditionPathExists=!/etc/cni/net.d/10-calico.conf

        [Service]
        RemainAfterExit=yes
        ExecStartPre=/opt/bin/kubectl get po
        ExecStart=/usr/bin/bash -c "wget -N -P /root http://iPXE_Server_IP/soft/kubeadm-anatomy.tgz && \
            PATH=$PATH:/opt/bin && tar xzvf /root/kubeadm-anatomy.tgz -C /root && \
            cd /root/kubeadm-anatomy/calico && \
            ETCD_IP=ServerIPAddress envsubst < calico-config.yml | kubectl apply -f - && \
            kubectl apply -f calico-node-daemonset.yml && \
            kubectl apply -f configure-calico.yml && \
            kubectl apply -f calico-policy-controller.yml"
        Restart=always
        RestartSec=5

        [Install]
        WantedBy=multi-user.target

#    - name: gluster-daemonset-installd.service
#      command: start
#      content: |
#        [Unit]
#        After=calico-installd.service
#        ConditionPathExists=/etc/cni/net.d/10-calico.conf

#        [Service]
#        RemainAfterExit=yes
#        ExecStart=/opt/bin/kubectl create -f /root/k8s/glusterfs.yml
#        Restart=always
#        RestartSec=5

users:
  - name: andrew
    passwd: $1$cxDrcmk0$B/WI7rG8E4THMzpkyPe.q.
    groups:
      - sudo
      - docker
  - name: inu
    passwd: "$6$rounds=4096$yTXdzXEJJzKRX74$Nxo6drS5qdJVpV5C.RqVE2ufRwqq./62xrKRXws4tWI0KM1jMPjt.DbESTdDdzHMYIbbkMeGUQa6j4Ow0Rar7."
    groups:
      - sudo
      - docker
